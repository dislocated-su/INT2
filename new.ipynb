{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7k2_2BPey4_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuTmokcBey5D"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt # for plotting\n",
        "import numpy as np # for transformation\n",
        "\n",
        "import torch # PyTorch package\n",
        "import torchvision # load datasets\n",
        "import torchvision.transforms as transforms # transform data\n",
        "import torch.nn as nn # basic building block for neural neteorks\n",
        "import torch.nn.functional as F # import convolution functions like Relu\n",
        "import torch.optim as optim # optimzer\n",
        "from tqdm import tqdm\n",
        "import torch.utils.data as U\n",
        "import json\n",
        "\n",
        "if (torch.cuda.is_available()):\n",
        "    torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"flower_classes.json\", \"r\") as f:\n",
        "    classes = json.load(f)\n",
        "classes = list(classes.values())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hyperparameters\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Means and stds for flowers dataset\n",
        "means, stds = (0.433, 0.382, 0.296), (0.262, 0.213, 0.225)\n",
        "\n",
        "batch_size = 16\n",
        "EPOCHS = 30\n",
        "\n",
        "# for SGD\n",
        "LEARNING_RATE =0.005\n",
        "MOMENTUM=0.9"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vDJehZdey5E"
      },
      "outputs": [],
      "source": [
        "def imshow(img, title=None):\n",
        "  ''' function to show image '''\n",
        "  img = img / 2 + 0.5 # unnormalize\n",
        "  npimg = img.numpy() # convert to numpy objects\n",
        "  ax = plt.subplot() \n",
        "  ax.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "  if (title is not None):\n",
        "    ax.set_title(title)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZD3pLs3Vey5F"
      },
      "outputs": [],
      "source": [
        "y = np.array(classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXzNGB_key5G"
      },
      "outputs": [],
      "source": [
        "# base transform\n",
        "transform_no_aug = transforms.Compose([\n",
        "\ttransforms.CenterCrop(size=500),\n",
        "\ttransforms.Resize((256,256)), \n",
        "\ttransforms.ToTensor(), # to tensor object\n",
        "\ttransforms.Normalize(means, stds)]) # mean, std over rbg values\n",
        "\n",
        "# flip (p=1)\n",
        "transform_flip = transforms.Compose([\n",
        "\ttransforms.CenterCrop(size=500),\n",
        "\ttransforms.Resize((256,256)), \n",
        "\ttransforms.ToTensor(), # to tensor object\n",
        "\ttransforms.Normalize(means,stds), # mean = 0.5, std = 0.5\n",
        "  transforms.RandomHorizontalFlip(1.0)]) # definite horizontal flip, probability = 1.0\n",
        "\n",
        "# rotation\n",
        "transform_rotate = transforms.Compose([\n",
        "\ttransforms.CenterCrop(size=500),\n",
        "\ttransforms.Resize((256,256)), \n",
        "\ttransforms.ToTensor(), # to tensor object\n",
        "\ttransforms.Normalize(means,stds), # mean = 0.5, std = 0.5\n",
        "  \ttransforms.RandomRotation(degrees = (-45, 45))]) # definite rotation between -45 degrees and 45 degrees\n",
        "\n",
        "# multiple augmentations\n",
        "transform_flip_rotate = transforms.Compose([\n",
        "\ttransforms.CenterCrop(size=500),\n",
        "\ttransforms.Resize((256,256)), \n",
        "\ttransforms.ToTensor(), # to tensor object\n",
        "\ttransforms.Normalize(means,stds), # mean = 0.5, std = 0.5\n",
        "  \ttransforms.RandomHorizontalFlip(0.5), \n",
        "\ttransforms.RandomRotation(degrees = (-90, 90))]) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9bQaGCiey5H"
      },
      "outputs": [],
      "source": [
        "# load train data\n",
        "set_no_aug = torchvision.datasets.Flowers102(root='./data', split=\"train\",\n",
        "\t\t\t\t\t\t\t\t\t\tdownload=True, transform=transform_no_aug)\n",
        "\n",
        "set_flip = torchvision.datasets.Flowers102(root='./data', split=\"train\",\n",
        "                                                download = True, transform = transform_flip)\n",
        "\n",
        "set_rotate = torchvision.datasets.Flowers102(root='./data', split=\"train\",\n",
        "                                                download = True, transform = transform_rotate)\n",
        "\n",
        "set_flip_rotate = torchvision.datasets.Flowers102(root='./data', split=\"train\",\n",
        "                                                download = True, transform = transform_flip_rotate)\n",
        "\n",
        "\n",
        "\n",
        "trainset = U.ConcatDataset([set_no_aug,  set_flip, set_rotate, set_flip_rotate])\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load test data\n",
        "testset = torchvision.datasets.Flowers102(root='./data', split=\"test\",\n",
        "\t\t\t\t\t\t\t\t\t\t download=True, transform=transform_no_aug)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "\t\t\t\t\t\t\t\t\t\t shuffle=False)\n",
        "\n",
        "#load valid data\n",
        "validset = torchvision.datasets.Flowers102(root='./data', split=\"val\",\n",
        "\t\t\t\t\t\t\t\t\t\t download=True, transform=transform_no_aug)\n",
        "validloader = torch.utils.data.DataLoader(validset, batch_size=batch_size,\n",
        "\t\t\t\t\t\t\t\t\t\t shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "4BuFAjpiey5I",
        "outputId": "48ef6bd4-e6de-4846-b170-b09bd9667f25"
      },
      "outputs": [],
      "source": [
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "# call function on our images\n",
        "imshow(torchvision.utils.make_grid(images), np.apply_along_axis('   '.join, 0 ,y[labels]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejhilFYSey5J"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, num_channels, classes):\n",
        "        super(Net, self).__init__() \n",
        "        self.features = nn.Sequential (\n",
        "            nn.Conv2d(in_channels=num_channels, out_channels=32, kernel_size=(3,3)),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(num_features=32),\n",
        "            \n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3)),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(num_features=64),\n",
        "            nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)),\n",
        "            \n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3)),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(num_features=128),\n",
        "            nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)),\n",
        "            \n",
        "            nn.Conv2d(in_channels=128, out_channels=64, kernel_size=(3,3)),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(num_features=64),\n",
        "            nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(in_features=64 * 30 * 30, out_features=4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(in_features=4096, out_features=1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(in_features=1024, out_features=classes),\n",
        "            nn.LogSoftmax(dim=1)    \n",
        "        )\n",
        "\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.shape[0], -1) \n",
        "        output = self.classifier(x)\n",
        "        return output  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AH1LvXCSey5K"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTTJH7bbmeql"
      },
      "outputs": [],
      "source": [
        "def calculate_accuracy(y_pred, y):\n",
        "    top_pred = y_pred.argmax(1, keepdim=True)\n",
        "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "    acc = correct.float() / y.shape[0]\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ir_Y-pZey5M"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion, device):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for (x, y) in tqdm(iterator, desc=\"TRAIN PROGRESS:\", total=int(len(iterator.dataset) / batch_size), leave=False):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.autocast(device_type='cuda'):\n",
        "            y_pred = model.forward(x)\n",
        "            loss = criterion(y_pred, y)\n",
        "            acc = calculate_accuracy(y_pred, y)\n",
        "        \n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += float(loss.cpu().item())\n",
        "        epoch_acc += float(acc.cpu().item())\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def testing(model, iterator, criterion, device):\n",
        "  total_loss = 0\n",
        "  total_acc = 0\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for images, labels in iterator:\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      pred_y= model.forward(images)\n",
        "\n",
        "      loss = criterion(pred_y, labels)\n",
        "      acc = calculate_accuracy(pred_y, labels)\n",
        "\n",
        "      total_loss += float(loss.cpu())\n",
        "      total_acc += float(acc.cpu())\n",
        "\n",
        "    return total_loss / len(iterator), total_acc / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7X_GucHKey5N",
        "outputId": "447fc410-e86d-476e-c269-ec40244da538"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = Net(3, len(classes))\n",
        "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)\n",
        "count_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if (True):\n",
        "    x = images.to(device)\n",
        "    x = model.features(x)\n",
        "    print(x.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqgBfhoSey5O"
      },
      "outputs": [],
      "source": [
        "epoch_loss, epoch_acc = train(model, trainloader, optimizer, criterion, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ng58YinplnvZ",
        "outputId": "7caa33dd-0f27-498f-e1bc-f1b90211888a"
      },
      "outputs": [],
      "source": [
        "print(epoch_loss)\n",
        "print(epoch_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISf0ZGBonyTp",
        "outputId": "56da1ab4-881b-42a8-a303-f08b180ba278"
      },
      "outputs": [],
      "source": [
        "\n",
        "best_valid_loss = float('inf')\n",
        "useful_info_dict = {\n",
        "                \"train_loss\" : [],\n",
        "                \"train_acc\" : [],\n",
        "                \"valid_loss\" : [],\n",
        "                \"valid_acc\" : []\n",
        "                  }\n",
        "\n",
        "for epoch in tqdm(range(EPOCHS), desc=\"EPOCH PROGRESS:\"):\n",
        "\n",
        "    train_loss, train_acc = train(model, trainloader, optimizer, criterion, device)\n",
        "    valid_loss, valid_acc = testing(model, validloader, criterion, device)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "      best_valid_loss = valid_loss\n",
        "      torch.save(model.state_dict(), 'best-model.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02}')\n",
        "    \n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    useful_info_dict[\"train_loss\"].append(train_loss)\n",
        "    useful_info_dict[\"train_acc\"].append(train_acc)\n",
        "    \n",
        "    print(f'\\tValid Loss: {valid_loss:.3f} | Valid Acc: {valid_acc*100:.2f}%')\n",
        "    useful_info_dict[\"valid_loss\"].append(valid_loss)\n",
        "    useful_info_dict[\"valid_acc\"].append(valid_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skWPrs8apm7l"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load('best-model.pt'))\n",
        "\n",
        "testing_loss, testing_acc = testing(model, testloader, criterion, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QS_AoxlrzH7",
        "outputId": "f60ef90d-f0aa-4704-d3aa-55f7961346e3"
      },
      "outputs": [],
      "source": [
        "print(testing_loss, testing_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_loss_and_acc(useful_info):\n",
        "    train_loss = useful_info[\"train_loss\"]\n",
        "    train_acc = useful_info[\"train_acc\"]\n",
        "    \n",
        "    val_loss = useful_info[\"valid_loss\"]\n",
        "    val_acc = useful_info[\"valid_acc\"]\n",
        "    fig, ax = plt.subplots()\n",
        "    \n",
        "    ax.set_title(\"Loss and accuracy over epochs\")\n",
        "\n",
        "    train_loss_line = ax.plot(train_loss, label=\"Train loss\")\n",
        "    train_acc_line = ax.plot(train_acc, label=\"Train accuracy\")\n",
        "    val_loss_line = ax.plot(val_loss, label=\"Valid loss\")\n",
        "    val_acc_line = ax.plot(val_acc, label=\"Valid accuracy\")\n",
        "    \n",
        "    # train_loss_line.set_label(\"Train Loss\")\n",
        "    # train_acc_line.set_label(\"Train Accuracy\")\n",
        "    # val_loss_line.set_label(\"Valid Loss\")\n",
        "    # val_acc_line.set_label(\"Valid Accuracy\")\n",
        "    \n",
        "    fig.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_loss_and_acc(useful_info_dict)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "int2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
